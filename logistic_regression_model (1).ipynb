{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28d7855f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "0\n",
      "                Time            V1            V2            V3            V4  \\\n",
      "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
      "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
      "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
      "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
      "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
      "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
      "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
      "\n",
      "                 V5            V6            V7            V8            V9  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
      "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
      "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
      "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
      "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
      "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
      "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
      "\n",
      "       ...           V21           V22           V23           V24  \\\n",
      "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
      "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
      "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
      "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
      "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
      "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
      "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
      "\n",
      "                V25           V26           V27           V28         Amount  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
      "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
      "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
      "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
      "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
      "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
      "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
      "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
      "\n",
      "               Class  \n",
      "count  284807.000000  \n",
      "mean        0.001727  \n",
      "std         0.041527  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n",
      "Label distributions: \n",
      "\n",
      "[0.99827072 0.00172928]\n",
      "[0.99827946 0.00172054]\n",
      "Training and evaluating Logistic Regression...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95        88\n",
      "           1       0.99      0.92      0.95       109\n",
      "\n",
      "    accuracy                           0.95       197\n",
      "   macro avg       0.95      0.95      0.95       197\n",
      "weighted avg       0.95      0.95      0.95       197\n",
      "\n",
      "Accuracy:  0.949238578680203\n",
      "Precision:  0.9900990099009901\n",
      "Recall:  0.9174311926605505\n",
      "F1 Score:  0.9523809523809524\n",
      "ROC AUC:  0.953033778148457\n",
      "------------------------------------\n",
      "Training and evaluating K-Nearest Neighbors...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        88\n",
      "           1       0.99      0.89      0.94       109\n",
      "\n",
      "    accuracy                           0.93       197\n",
      "   macro avg       0.93      0.94      0.93       197\n",
      "weighted avg       0.94      0.93      0.93       197\n",
      "\n",
      "Accuracy:  0.934010152284264\n",
      "Precision:  0.9897959183673469\n",
      "Recall:  0.8899082568807339\n",
      "F1 Score:  0.9371980676328503\n",
      "ROC AUC:  0.9392723102585487\n",
      "------------------------------------\n",
      "Training and evaluating Decision Tree...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89        88\n",
      "           1       0.91      0.92      0.91       109\n",
      "\n",
      "    accuracy                           0.90       197\n",
      "   macro avg       0.90      0.90      0.90       197\n",
      "weighted avg       0.90      0.90      0.90       197\n",
      "\n",
      "Accuracy:  0.9035532994923858\n",
      "Precision:  0.9090909090909091\n",
      "Recall:  0.9174311926605505\n",
      "F1 Score:  0.9132420091324202\n",
      "ROC AUC:  0.9018974145120934\n",
      "------------------------------------\n",
      "Training and evaluating Random Forest...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        88\n",
      "           1       1.00      0.92      0.96       109\n",
      "\n",
      "    accuracy                           0.95       197\n",
      "   macro avg       0.95      0.96      0.95       197\n",
      "weighted avg       0.96      0.95      0.95       197\n",
      "\n",
      "Accuracy:  0.9543147208121827\n",
      "Precision:  1.0\n",
      "Recall:  0.9174311926605505\n",
      "F1 Score:  0.9569377990430622\n",
      "ROC AUC:  0.9587155963302753\n",
      "------------------------------------\n",
      "Training and evaluating Support Vector Machine...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92        88\n",
      "           1       0.99      0.87      0.93       109\n",
      "\n",
      "    accuracy                           0.92       197\n",
      "   macro avg       0.93      0.93      0.92       197\n",
      "weighted avg       0.93      0.92      0.92       197\n",
      "\n",
      "Accuracy:  0.9238578680203046\n",
      "Precision:  0.9895833333333334\n",
      "Recall:  0.8715596330275229\n",
      "F1 Score:  0.9268292682926829\n",
      "ROC AUC:  0.9300979983319432\n",
      "------------------------------------\n",
      "Training and evaluating Stochastic Gradient Descent...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91        88\n",
      "           1       0.94      0.91      0.93       109\n",
      "\n",
      "    accuracy                           0.92       197\n",
      "   macro avg       0.92      0.92      0.92       197\n",
      "weighted avg       0.92      0.92      0.92       197\n",
      "\n",
      "Accuracy:  0.9187817258883249\n",
      "Precision:  0.9428571428571428\n",
      "Recall:  0.908256880733945\n",
      "F1 Score:  0.9252336448598131\n",
      "ROC AUC:  0.9200375312760635\n",
      "------------------------------------\n",
      "Training and evaluating Stacking Classifier...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        88\n",
      "           1       1.00      0.91      0.95       109\n",
      "\n",
      "    accuracy                           0.95       197\n",
      "   macro avg       0.95      0.95      0.95       197\n",
      "weighted avg       0.95      0.95      0.95       197\n",
      "\n",
      "Accuracy:  0.949238578680203\n",
      "Precision:  1.0\n",
      "Recall:  0.908256880733945\n",
      "F1 Score:  0.9519230769230769\n",
      "ROC AUC:  0.9541284403669725\n",
      "------------------------------------\n",
      "The best model is Random Forest with an accuracy of 0.9543147208121827\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Load the logistic regression model\n",
    "logistic_regression_model = joblib.load(r'C:\\Users\\yordi\\Credit-card-fraud-detection-master\\logistic_regression_model.pkl')\n",
    "\n",
    "# Read Data into a Dataframe\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# Display basic information and check for missing values\n",
    "print(df.shape)\n",
    "print(df.isnull().sum().sum())\n",
    "\n",
    "# Descriptive statistics\n",
    "print(df.describe())\n",
    "# Drop high amount transactions\n",
    "df = df[df['Amount'] < 10000]\n",
    "\n",
    "# Feature Scaling using RobustScaler\n",
    "rob_scaler = RobustScaler()\n",
    "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1, 1))\n",
    "df.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "scaled_amount = df['scaled_amount']\n",
    "df.drop(['scaled_amount'], axis=1, inplace=True)\n",
    "df.insert(0, 'scaled_amount', scaled_amount)\n",
    "\n",
    "# Splitting the dataset\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "# Converting to arrays\n",
    "original_Xtrain = original_Xtrain.values\n",
    "original_Xtest = original_Xtest.values\n",
    "original_ytrain = original_ytrain.values\n",
    "original_ytest = original_ytest.values\n",
    "\n",
    "# Check class distribution in train and test sets\n",
    "train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\n",
    "test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\n",
    "print(\"Label distributions: \\n\")\n",
    "print(train_counts_label / len(original_ytrain))\n",
    "print(test_counts_label / len(original_ytest))\n",
    "\n",
    "# Undersampling the dataset to balance class distribution\n",
    "df = df.sample(frac=1)\n",
    "fraud_df = df.loc[df['Class'] == 1]\n",
    "non_fraud_df = df.loc[df['Class'] == 0][:492]\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "new_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Outlier detection and removal\n",
    "def remove_outliers(df, feature):\n",
    "    fraud = df[feature].loc[df['Class'] == 1].values\n",
    "    q25, q75 = np.percentile(fraud, 25), np.percentile(fraud, 75)\n",
    "    iqr = q75 - q25\n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    df = df.drop(df[(df[feature] > upper) | (df[feature] < lower)].index)\n",
    "    return df\n",
    "\n",
    "new_df = remove_outliers(new_df, 'V14')\n",
    "new_df = remove_outliers(new_df, 'V12')\n",
    "new_df = remove_outliers(new_df, 'V10')\n",
    "\n",
    "# Dimensionality Reduction\n",
    "X = new_df.drop('Class', axis=1)\n",
    "y = new_df['Class']\n",
    "\n",
    "# Resampling (SMOTE)\n",
    "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Evaluation Helper Function\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "    print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "    print(\"F1 Score: \", f1_score(y_test, y_pred))\n",
    "    print(\"ROC AUC: \", roc_auc_score(y_test, y_pred))\n",
    "    return accuracy\n",
    "\n",
    "# Define algorithms\n",
    "estimators = [\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('svm', SVC(probability=True))\n",
    "]\n",
    "algorithms = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Stochastic Gradient Descent': SGDClassifier(),\n",
    "    'Stacking Classifier': StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "}\n",
    "\n",
    "# Dictionary to store accuracy scores\n",
    "accuracy_scores = {}\n",
    "\n",
    "# Evaluate each model\n",
    "for name, model in algorithms.items():\n",
    "    print(f\"Training and evaluating {name}...\")\n",
    "    accuracy = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    accuracy_scores[name] = accuracy\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "# Select the best model based on accuracy\n",
    "best_model_name = max(accuracy_scores, key=accuracy_scores.get)\n",
    "best_model = algorithms[best_model_name]\n",
    "print(f\"The best model is {best_model_name} with an accuracy of {accuracy_scores[best_model_name]}\")\n",
    "\n",
    "# Example: Using the best model for prediction\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Save the updated model\n",
    "joblib.dump(best_model, r'C:\\Users\\yordi\\Credit-card-fraud-detection-master\\logistic_regression_model.pkl')\n",
    "\n",
    "print(\"Model updated and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1a73b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
